[["index.html", "Homework 1 1 Textbook Exercises 1.1 Exercise 2.6 1.2 Exercise 2.8 1.3 Exercise 2.14 1.4 Exercise 2.25 1.5 Exercise 3.2 1.6 Exercise 3.3 1.7 Exercise 3.4 1.8 Exercise 3.9 1.9 Exercise 3.13", " Homework 1 Chi-Yuan Fang 2021-02-25 1 Textbook Exercises Do the following problem sets from Stock &amp; Watson (4th Edition). 2.6, 2.8, 2.14, 2.25, 3.2, 3.3, 3.4, 3.9, 3.13 1.1 Exercise 2.6 \\[\\begin{align} E(Y) &amp; = 0\\cdot 0.12 + 1\\cdot 0.88 = 0.88 \\end{align}\\] \\[\\begin{align} Pr(Y = 0) &amp; = 1 - Pr(Y = 1) \\\\ &amp; = 1 - E(Y) \\\\ &amp; = 1 - 0.88 = 0.12 \\end{align}\\] The conditional probabilities are \\[\\begin{align} Pr(Y = 0 \\lvert X = 0) &amp; = \\frac{Pr(X=0,Y=0)}{Pr(X=0)} \\\\ &amp; = \\frac{0.078}{0.751} = \\frac{78}{751} \\\\ Pr(Y = 1 \\lvert X = 0) &amp; = \\frac{Pr(X=0,Y=1)}{Pr(X=0)} \\\\ &amp; = \\frac{0.673}{0.751} = \\frac{673}{751} \\\\ Pr(Y = 0 \\lvert X = 1) &amp; = \\frac{Pr(X=1,Y=0)}{Pr(X=1)} \\\\ &amp; = \\frac{0.042}{0.249} = \\frac{14}{83} \\\\ Pr(Y = 1 \\lvert X = 1) &amp; = \\frac{Pr(X=1,Y=1)}{Pr(X=1)} \\\\ &amp; = \\frac{0.207}{0.249} = \\frac{69}{83}. \\end{align}\\] Then, the conditional expectations are \\[\\begin{align} E(Y \\lvert X = 1) &amp; = 0\\cdot \\frac{14}{83} + 1\\cdot \\frac{69}{83} = \\frac{69}{83} \\approx 0.8313 \\\\ E(Y \\lvert X = 0) &amp; = 0\\cdot \\frac{78}{751} + 1\\cdot \\frac{673}{751} = \\frac{673}{751} \\approx 0.8961. \\end{align}\\] Unemployment rate for college graduates is \\[\\begin{align} Pr(Y = 0 \\lvert X = 1) &amp; = 1 - E(Y \\lvert X = 1) \\\\ &amp; = 1 - \\frac{69}{83} \\\\ &amp; = \\frac{14}{83} \\approx 0.1687, \\end{align}\\] and unemployment rate for non-college graduates is \\[\\begin{align} Pr(Y = 0 \\lvert X = 0) &amp; = 1 - E(Y \\lvert X = 0) \\\\ &amp; = 1 - \\frac{673}{751} \\\\ &amp; = \\frac{78}{751} \\approx 0.1039. \\end{align}\\] Given a randomly selected member of unemployed population, the probability that the worker is a college graduate is \\[\\begin{align} Pr(X = 1 \\lvert Y = 0) &amp; = \\frac{Pr(X = 1, Y = 0)}{Pr(Y = 0)} \\\\ &amp; = \\frac{0.042}{0.12} = 0.35, \\end{align}\\] and the probability that the worker is a non-college graduate is \\[\\begin{align} Pr(X = 0 \\lvert Y = 0) &amp; = \\frac{Pr(X = 0, Y = 0)}{Pr(Y = 0)} \\\\ &amp; = \\frac{0.078}{0.12} = 0.65. \\end{align}\\] Because \\[\\begin{align} Pr(X = 0\\lvert Y = 0) &amp; = \\frac{78}{751} \\\\ &amp; \\neq Pr(X = 0) = 0.12, \\end{align}\\] educational achievement and employment status are not independent. 1.2 Exercise 2.8 We know \\[\\begin{align} E(Y) = 4 \\quad \\mbox{and} \\quad Var(Y) = \\frac{1}{9}. \\end{align}\\] Then, \\[\\begin{align} E(Z) &amp; = E\\left[ 3(Y - 4) \\right] \\\\ &amp; = 3E(Y - 4) \\\\ &amp; = 3E(Y) - 12 \\\\ &amp; = 3\\cdot 4 - 12 = 0 \\end{align}\\] and \\[\\begin{align} Var(Z) &amp; = Var\\left[ 3(Y - 4) \\right] \\\\ &amp; = 3^2 \\cdot Var(Y - 4) \\\\ &amp; = 9\\cdot Var(Y) \\\\ &amp; = 9\\cdot \\frac{1}{9} = 1. \\end{align}\\] 1.3 Exercise 2.14 By CLT, we have \\[\\begin{align} \\overline{Y} \\sim N\\left(\\mu_Y, \\frac{\\sigma_Y^2}{n}\\right) \\stackrel{d}{=} N\\left(50, \\frac{21}{n} \\right). \\end{align}\\] \\[\\begin{align} Pr\\left( \\overline{Y}\\leq 51 \\right) &amp; = Pr\\left( \\frac{\\overline{Y} - 50}{\\sqrt{21/50}} \\leq \\frac{51 - 50}{\\sqrt{21/50}}\\right) \\approx 0.9386 \\end{align}\\] \\[\\begin{align} Pr\\left( \\overline{Y} &gt; 49 \\right) &amp; = Pr\\left( \\frac{\\overline{Y} - 50}{\\sqrt{21/150}} &gt; \\frac{49 - 50}{\\sqrt{21/150}}\\right) \\approx 0.9962 \\end{align}\\] \\[\\begin{align} Pr\\left( 50.5 \\leq \\overline{Y} &lt; 51 \\right) &amp; = Pr\\left( \\frac{50.5 - 50}{\\sqrt{21/45}} \\leq \\overline{Y} \\leq \\frac{51 - 50}{\\sqrt{21/45}}\\right) \\approx 0.1605 \\end{align}\\] 1.4 Exercise 2.25 \\[\\begin{align} \\sum_{i=1}^{n}ax_i &amp; = ax_1 + ax_2 + \\ldots + ax_n \\\\ &amp; = a(x_1 + x_2 + \\ldots + x_n) \\\\ &amp; = a\\sum_{i=1}^{n}x_i \\end{align}\\] \\[\\begin{align} \\sum_{i=1}^{n}(x_i + y_i) &amp; = (x_1 + y_1) + (x_2 + y_2) + \\ldots + (x_n + y_n) \\\\ &amp; = (x_1 + x_2 + \\ldots + x_n) + (y_1 + y_2 + \\ldots + y_n) \\\\ &amp; = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i \\end{align}\\] \\[\\begin{align} \\sum_{i=1}^{n} a &amp; = \\underbrace{a + a + \\ldots + a}_{n\\mbox{ times}} \\\\ &amp; = n\\times a \\end{align}\\] \\[\\begin{align} \\sum_{i=1}^{n} (a + bx_i + cy_i)^2 &amp; = \\sum_{i=1}^{n} \\left( a^2 + b^2x_i^2 + c^2y_i^2 + 2abx_i + 2acy_i + 2bcx_iy_i \\right) \\\\ &amp; = na^2 + b^2\\sum_{i=1}^{n}x_i^2 + c^2\\sum_{i=1}^{n}y_i^2 + 2ab\\sum_{i=1}^{n}x_i + 2ac\\sum_{i=1}^{n}y_i + 2bc\\sum_{i=1}^{n}x_iy_i \\end{align}\\] 1.5 Exercise 3.2 \\[\\begin{align} \\widehat{p} &amp; = \\frac{1}{n} \\sum_{i=1}^{n}Y_i = \\overline{Y} \\end{align}\\] \\[\\begin{align} E\\left( \\widehat{p} \\right) &amp; = E\\left( \\overline{Y} \\right) \\\\ &amp; = E\\left( \\frac{1}{n}\\sum_{i=1}^{n} Y_i \\right) \\\\ &amp; = \\frac{1}{n} E\\left( \\sum_{i=1}^{n} Y_i \\right) \\\\ &amp; = \\frac{1}{n} \\sum_{i=1}^{n} E(Y_i) \\\\ &amp; = \\frac{1}{n}\\cdot np = p \\end{align}\\] \\[\\begin{align} Var\\left( \\widehat{p} \\right) &amp; = Var\\left( \\overline{Y} \\right) \\\\ &amp; = Var\\left( \\frac{1}{n}\\sum_{i=1}^{n}Y_i \\right) \\\\ &amp; = \\frac{1}{n^2} Var\\left( \\sum_{i=1}^{n}Y_i \\right) \\\\ &amp; = \\frac{1}{n^2} \\left[ nVar(Y_i) + 2\\sum_{i\\neq j} \\underbrace{Cov (Y_i, Y_j)}_{=0} \\right] \\\\ &amp; = \\frac{1}{n^2} \\cdot np(1-p) = \\frac{p(1-p)}{n} \\end{align}\\] 1.6 Exercise 3.3 \\[\\begin{align} \\widehat{p} &amp; = \\frac{270}{500} = 0.54 \\end{align}\\] The estimated variance of \\(\\widehat{p}\\) is \\[\\begin{align} Var\\left( \\widehat{p} \\right) &amp; = \\frac{\\widehat{p} \\left( 1 -\\widehat{p} \\right)}{n} \\\\ &amp; = \\frac{0.54(1-0.54)}{500} = 0.0004968, \\end{align}\\] and the standard error is \\[\\begin{align} SE\\left( \\widehat{p} \\right) &amp; = \\sqrt{Var\\left( \\widehat{p} \\right)} \\\\ &amp; \\approx 0.0223. \\end{align}\\] The \\(t\\)-statistic is \\[\\begin{align} t^* &amp; = \\frac{\\widehat{p} - p_0}{SE\\left( \\widehat{p} \\right)} \\\\ &amp; = \\frac{0.54 - 0.5}{0.0223} \\\\ &amp; = \\frac{400}{223} \\approx 1.7937. \\end{align}\\] Then, \\[\\begin{align} p-value &amp; = 2\\Phi \\left( -\\lvert{t^*}\\lvert \\right) \\\\ &amp; = 2\\Phi \\left( -\\frac{400}{223} \\right) \\approx 0.0729. \\end{align}\\] The \\(t\\)-statistic is \\[\\begin{align} t^* &amp; = \\frac{\\widehat{p} - p_0}{SE\\left( \\widehat{p} \\right)} \\\\ &amp; = \\frac{0.54 - 0.5}{0.0223} \\\\ &amp; = \\frac{400}{223} \\approx 1.7937. \\end{align}\\] Then, \\[\\begin{align} p-value &amp; = 1 - \\Phi \\left( \\lvert{t^*}\\lvert \\right) \\\\ &amp; = 1 - \\Phi \\left( \\frac{400}{223} \\right) \\approx 0.0364. \\end{align}\\] Part (c) is a two-sided test and the p-value is the area in the tails of the standard normal distribution outside the \\(\\pm\\) (calculated \\(t\\)-statistic). Part (d) is a one-sided test and the p-value is the area under the standard normal distribution to the right of the calculated \\(t\\)-statistic. For the test \\(H_0: p = 0.5\\) vs. \\(H_1: p &gt; 0.5\\) and \\(\\alpha = 0.05\\), we reject \\(H_0\\) because \\(p\\)-value is less than the significance level. There is statistically significant evidence that the democratic candidate was ahead of the republican candidate at the time of conducting the poll. 1.7 Exercise 3.4 \\[\\begin{align} \\overline{p} \\pm Z_{0.025}SE\\left( \\overline{p} \\right) &amp; = 0.54 \\pm 1.96\\cdot 0.0223 \\approx [0.4963,0.5837] \\end{align}\\] \\[\\begin{align} \\overline{p} \\pm Z_{0.005}SE\\left( \\overline{p} \\right) &amp; = 0.54 \\pm 2.576\\cdot 0.0223 \\approx [0.4826,0.5974] \\end{align}\\] Mechanically, the interval in part (b) is wider because of a larger critical value. Substantively, a 99% confidence interval is wider than a 95% confidence level because a 99% confidence interval must contain the true value of \\(p\\) in 99% of all possible samples, while a 95% confidence interval must contain the true value of \\(p\\) in only 95% of all possible samples. Because \\(0.5\\in C.I.\\), we do not reject \\(H_0\\) at \\(5\\%\\) significance level. 1.8 Exercise 3.9 We know \\[\\begin{align} E(Y) &amp; = 1000 \\\\ \\sigma_Y &amp; = 100 \\\\ n &amp; = 50 \\end{align}\\] and \\[\\begin{align} E\\left(\\overline{Y} \\right) &amp; = 1000 \\\\ \\sigma_{\\overline{Y}} &amp; = \\frac{100}{\\sqrt{50}} = 10\\sqrt{2}. \\end{align}\\] Then, \\[\\begin{align} \\mbox{size} &amp; = \\Pr\\left( \\overline{Y} &gt; 1100 \\lvert \\mu = 1000 \\right) \\\\ &amp; = \\Pr\\left( \\frac{\\overline{Y} - 1000}{10\\sqrt{2}} &gt; \\frac{1100 - 1000}{10\\sqrt{2}} \\right) \\approx 0. \\end{align}\\] The probability of type 2 error is \\[\\begin{align} \\beta &amp; = \\Pr\\left( \\overline{Y} \\lvert \\mu = 1150 \\right) \\\\ &amp; = \\Pr\\left( \\frac{\\overline{Y} - 1150}{10\\sqrt{2}} \\leq \\frac{1100 - 1150}{10\\sqrt{2}} \\right) \\approx 0.0002. \\end{align}\\] Then, the power of the manager’s testing is \\[\\begin{align} 1-\\beta &amp; \\approx 0.9998. \\end{align}\\] For a test with size 1%, the rejection region for \\(H_0\\) contains those values of the \\(t\\)-statistic exceeding \\(Z_{0.01}\\). That is, \\[\\begin{align} t^* &amp; = \\frac{\\overline{Y} - 1000}{10\\sqrt{2}} &gt; Z_{0.01} = 2.326. \\end{align}\\] Then, \\[\\begin{align} \\overline{Y} &amp; &gt; 1000 + 10\\sqrt{2}\\cdot 2.326 \\approx 1032.8946. \\end{align}\\] Thus, the manager should believe the inventor’s claim if the sample mean life of the new product is greater than 1032.8946 hours if she wants the size of the test to be 1%. 1.9 Exercise 3.13 \\[\\begin{align} \\overline{Y} \\pm Z_{0.05}\\cdot \\frac{s_Y}{\\sqrt{n}} &amp; = 712.1 \\pm 1.645 \\cdot \\frac{23.2}{\\sqrt{400}} = [710.1918, 714.0082] \\end{align}\\] Prepare: \\(H_0: \\mu_1 - \\mu_2 = 0\\) vs. \\(H_1: \\mu_1 - \\mu_2 \\neq 0\\), where \\(\\mu_1\\) is average salary with small class, \\(\\mu_2\\) is average salary with large class. Let the significance level be \\(0.05\\). Calculate: \\[\\begin{align} t^* &amp; = \\frac{\\left( \\overline{Y}_1 - \\overline{Y}_2 \\right) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\ &amp; = \\frac{721.8 - 710.9}{\\sqrt{\\frac{24.4^2}{150}+ \\frac{20.6}{250}}} \\approx 4.5790 \\end{align}\\] Conclude: Because \\[\\begin{align} t^* &gt; Z_{0.025} = 1.96, \\end{align}\\] we reject \\(H_0\\). There is statistically significant evidence that districts with smaller classes have higher average test scores. "],["computer-exercises.html", "2 Computer exercises 2.1 E3.2", " 2 Computer exercises Do the following problem set from Stock &amp; Watson (4th Edition). E3.2 2.1 E3.2 A consumer is given the chance to buy a baseball card for $1, but he declines the trade. If the consumer is now given the baseball card, will he be willing to sell it for $1? Standard consumer theory suggests yes, but behavioral economists have found that “ownership” tends to increase the value of goods to consumers. That is, the consumer may hold out for some amount more than $1 (for example, $1.20) when selling the card, even though he was willing to pay only some amount less than $1 (for example, $0.88) when buying it. Behavioral economists call this phenomenon the “endowment effect.” John List investigated the endowment effect in a randomized experiment involving sports memorabilia traders at a sports-card show. Traders were randomly given one of two sports collectibles, say good A or good B, that had approximately equal market value. Those receiving good A were then given the option of trading good A for good B with the experimenter; those receiving good B were given the option of trading good B for good A with the experimenter. Data from the experiment and a detailed description can be found on the text website, http://www.pearsonglobaleditions.com, in the files Sportscards and Sportscards_Description. Suppose that, absent any endowment effect, all the subjects prefer good A to good B. What fraction of the experiment’s subjects would you expect to trade the good that they were given for the other good? (Hint: Because of random assignment of the two treatments, approximately 50% of the subjects received good A, and 50% received good B.) Suppose that, absent any endowment effect, 50% of the subjects prefer good A to good B, and the other 50% prefer good B to good A. What fraction of the subjects would you expect to trade the good they were given for the other good? Suppose that, absent any endowment effect, \\(X\\%\\) of the subjects prefer good A to good B, and the other \\((100 - X)\\%\\) prefer good B to good A. Show that you would expect 50% of the subjects to trade the good they were given for the other good. Solution A person will trade if he/she received good A but prefers good B or he/she received good B and prefers good A. 50% received good A, of these \\(100\\%\\) prefer good B; 50% receive good B, of these \\(0\\%\\) prefer good A. Thus, the expected fraction traded is \\[\\begin{align} 0.5 \\times 1 + 0.5\\times 0 = 0.5. \\end{align}\\] A person will trade if he/she received good A but prefers good B or he/she received good B and prefers good A. 50% received good A, of these \\(50\\%\\) prefer good B; 50% receive good B, of these \\(50\\%\\) prefer good A. Thus, the expected fraction traded is \\[\\begin{align} 0.5 \\times 0.5 + 0.5\\times 0.5 = 0.5. \\end{align}\\] A person will trade if he/she received good A but prefers good B or he/she received good B and prefers good A. 50% received good A, of these \\((100-X)\\%\\) prefer good B; 50% receive good B, of these \\(X\\%\\) prefer good A. Thus, the expected fraction traded is \\[\\begin{align} 0.5 \\times (1-x) + 0.5x = 0.5 \\end{align}\\] where \\(x = \\frac{X}{100}\\). Using the sports-card data, what fraction of the subjects traded the good they were given? Is the fraction significantly different from 50%? Is there evidence of an endowment effect? (Hint: Review Exercises 3.2 and 3.3.) Solution Prepare \\(H_0: p= 0.5\\) (no endowment effect) v.s. \\(H_A: p \\neq 0.5\\) (endowment effect), where \\(p\\) is the fraction of trades. Let the significance level be \\(0.05\\). Calculate # import data library(readxl) sportscards &lt;- read_xlsx(&quot;sportscards/Sportscards.xlsx&quot;) # the fraction of trades fract_trade &lt;- mean(sportscards$trade) fract_trade ## [1] 0.3378378 # standard error of the fraction of trades se_fract_trade &lt;- sd(sportscards$trade)/sqrt(length(sportscards$trade)) se_fract_trade ## [1] 0.03901015 # test t.test(sportscards$trade, alternative = c(&quot;two.sided&quot;), mu = 0.5, # H0 conf.level = 0.95) # alpha = 0.05 ## ## One Sample t-test ## ## data: sportscards$trade ## t = -4.1569, df = 147, p-value = 5.456e-05 ## alternative hypothesis: true mean is not equal to 0.5 ## 95 percent confidence interval: ## 0.2607447 0.4149310 ## sample estimates: ## mean of x ## 0.3378378 Conclude The fraction of trades in the sample was 0.3378, with a standard error of 0.0390. Because \\(p-value &lt; 0.05\\), we reject \\(H_0\\). There is statistically significant evidence of an endowment effect. Some have argued that the endowment effect may be present but that it is likely to disappear as traders gain more trading experience. Half of the experimental subjects were dealers, and the other half were nondealers. Dealers have more experience than nondealers. Repeat (b) for dealers and nondealers. Is there a significant difference in their behavior? Is the evidence consistent with the hypothesis that the endowment effect disappears as traders gain more experience? (Hint: Review Exercise 3.15.) Solution Dealers: Prepare \\(H_0: p_1 = 0.5\\) (no endowment effect) v.s. \\(H_A: p_1 \\neq 0.5\\) (endowment effect), where \\(p_1\\) is the fraction of trades for dealers. Let the significance level be \\(0.05\\). Calculate # dealer sportscards_dealer &lt;- sportscards[sportscards$dealer == 1,] # the fraction of trades for dealers fract_trade_dealer &lt;- mean(sportscards_dealer$trade) fract_trade_dealer ## [1] 0.4459459 # standard error of the fraction of trades for dealers se_fract_trade_dealer &lt;- sd(sportscards_dealer$trade)/sqrt(length(sportscards_dealer$trade)) se_fract_trade_dealer ## [1] 0.05817759 # test t.test(sportscards_dealer$trade, alternative = c(&quot;two.sided&quot;), mu = 0.5, # H0 conf.level = 0.95) # alpha = 0.05 ## ## One Sample t-test ## ## data: sportscards_dealer$trade ## t = -0.92912, df = 73, p-value = 0.3559 ## alternative hypothesis: true mean is not equal to 0.5 ## 95 percent confidence interval: ## 0.3299982 0.5618937 ## sample estimates: ## mean of x ## 0.4459459 Conclude The fraction of trades for dealers in the sample was 0.4459, with a standard error of 0.05818. Because \\(p-value &gt; 0.05\\), we don’t reject \\(H_0\\). There is no evidence of an endowment effect. Nondealers: Prepare \\(H_0: p_2 = 0.5\\) (no endowment effect) v.s. \\(H_A: p_2 \\neq 0.5\\) (endowment effect), where \\(p_2\\) is the fraction of trades for nondealers. Let the significance level be \\(0.05\\). Calculate # nondealer sportscards_nondealer &lt;- sportscards[sportscards$dealer == 0,] # the fraction of trades for nondealers fract_trade_nondealer &lt;- mean(sportscards_nondealer$trade) fract_trade_nondealer ## [1] 0.2297297 # standard error of the fraction of trades for nondealers se_fract_trade_nondealer &lt;- sd(sportscards_nondealer$trade)/sqrt(length(sportscards_nondealer$trade)) se_fract_trade_nondealer ## [1] 0.04923441 # test t.test(sportscards_nondealer$trade, alternative = c(&quot;two.sided&quot;), mu = 0.5, # H0 conf.level = 0.95) # alpha = 0.05 ## ## One Sample t-test ## ## data: sportscards_nondealer$trade ## t = -5.4895, df = 73, p-value = 5.559e-07 ## alternative hypothesis: true mean is not equal to 0.5 ## 95 percent confidence interval: ## 0.1316057 0.3278538 ## sample estimates: ## mean of x ## 0.2297297 Conclude The fraction of trades for nondealers in the sample was 0.2297, with a standard error of 0.0492. Because \\(p-value &lt; 0.05\\), we reject \\(H_0\\). There is statistically significant evidence of an endowment effect. Difference between dealers and nondealers: Prepare \\(H_0: p_1 - p_2 = 0\\) v.s. \\(H_A: p_1 - p_2 \\neq 0\\), where \\(p_1\\) is the fraction of trades for dealers, and \\(p_2\\) is the fraction of trades for nondealers. Let the significance level be \\(0.05\\). Calculate # difference trade_diff &lt;- sportscards_dealer$trade - sportscards_nondealer$trade # the fraction of trades for nondealers fract_trade_diff &lt;- mean(trade_diff) fract_trade_diff ## [1] 0.2162162 # standard error of the fraction of trades for nondealers se_fract_trade_diff &lt;- sd(trade_diff)/sqrt(length(trade_diff)) se_fract_trade_diff ## [1] 0.07268651 t.test(trade_diff, alternative = c(&quot;two.sided&quot;), mu = 0.5, # H0 conf.level = 0.95) # alpha = 0.05 ## ## One Sample t-test ## ## data: trade_diff ## t = -3.9042, df = 73, p-value = 0.0002088 ## alternative hypothesis: true mean is not equal to 0.5 ## 95 percent confidence interval: ## 0.07135221 0.36108022 ## sample estimates: ## mean of x ## 0.2162162 Conclude Because \\(p-value &lt; 0.05\\), we reject \\(H_0\\). There is statistically significant difference in the behavior of Traders and non-Traders. "],["introduction.html", "3 Introduction 3.1 TA Information 3.2 TA Sessions Schedule 3.3 Reference", " 3 Introduction 3.1 TA Information TA: Chi-Yuan Fang TA sessions: Tuesday 1:20 – 3:10 PM (SS 501) Email: r09323017@ntu.edu.tw Office hours: Tuesday 3:20 - 4:10 PM or by appointments (SS 643) Class group on Facebook: Statistics with Recitation (Fall 2020) https://www.facebook.com/groups/452292659024369/ Because screens are not clear in SS 501, I would provide live screen in the group. 3.2 TA Sessions Schedule Week TA Sessions Quiz Content Remind 1 09/15: No class 2 09/22: Class 1 Part 1: Introduction, Data Visualization 3 09/29: Class 2 Part 1 10/07 Turn in HW1 4 10/06: Class 3 Part 2: Distributions (1) 10/07 Turn in HW1, 10/13 Quiz 1 5 10/13: Class 4 Quiz 1 Part 2 10/21 Turn in HW2 6 10/20: Class 5 Part 3: Distributions (2) 10/21 Turn in HW2, 10/27 Quiz 2 7 10/27: Class 6 Quiz 2 Part 3 11/04 Turn in HW3 8 11/03: Class 7 Part 4: Test 11/04 Turn in HW3, 11/10 Quiz 3 9 11/10: Class 8 Quiz 3 Part 4 11/18 Midterm 10 11/17: Class 9 Review and Q&amp;A 11/18 Midterm, 11/25 Turn in HW4 11 11/24: Class 10 Part 5: Model (1) ANOVA 11/25 Turn in HW4, 12/01 Quiz 4 12 12/01: Class 11 Quiz 4 Part 5 12/09 Turn in HW5 13 12/08: Class 12 Part 6: Model (2) Regression 12/09 Turn in HW5, 12/15 Quiz 5 14 12/15: Class 13 Quiz 5 Part 6 12/23 Turn in HW6 15 12/22: Class 14 Review and Q&amp;A 12/23 Turn in HW6, 12/29 Quiz 6 16 12/29: Class 15 Quiz 6 Review and Q&amp;A 01/13 Final Exam 17 01/05: No class 01/13 Final Exam 18 01/12: No class 01/13 Final Exam 3.3 Reference What is a good book on learning R with examples? https://www.quora.com/What-is-a-good-book-on-learning-R-with-examples "],["data-set-possum.html", "4 Data Set: possum 4.1 Data Description 4.2 Input Data 4.3 Data Cleaning 4.4 Correlation 4.5 Graphical Analysis 4.6 Linear Regression", " 4 Data Set: possum 4.1 Data Description https://www.openintro.org/data/index.php?data=possum 4.1.1 Background Data representing possums in Australia and New Guinea. This is a copy of the data set by the same name in the DAAG package, however, the data set included here includes fewer variables. 4.1.2 Variables pop - Population, either Vic (Victoria) or other (New South Wales or Queensland). sex - Gender, either m (male) or f (female). age - Age. head_l - Head length, in mm. skull_w - Skull width, in mm. total_l - Total length, in cm. tail_l - Tail length, in cm. 4.2 Input Data 4.2.1 csv File # input data #possum_csv &lt;- read.csv(&#39;/Users/chi-yuan/Desktop/NTU ECON/Statistics/Stat/possum.csv&#39;) Remark How to get a file path on a Mac? Right-click the file Click Get Info 4.2.2 Package library(openintro) ## Loading required package: airports ## Loading required package: cherryblossom ## Loading required package: usdata #library(tidyverse) #data(COL) data(possum) 4.3 Data Cleaning 4.3.1 Remove Missing Values # return a logical vector indicating which cases are complete, i.e., have no missing values. possum_new &lt;- possum[complete.cases(possum),] 4.3.2 Delete Rows with Specific Condition(s) For example, we want to delete \\(site = 2\\) rows. possum_new2 &lt;- possum_new[possum_new$site != 2, ] 4.4 Correlation Calculate the correlation coefficient between x (total_l) and y (head_l). x &lt;- possum_new$total_l y &lt;- possum_new$head_l cor(x, y) ## [1] 0.6742892 4.5 Graphical Analysis 4.5.1 Scatter Plot Make a scatterplot for x (total_l) and y (head_l). scatter.smooth(x = x, y = y, xlab = &quot;Total Length (cm)&quot;, ylab = &quot;Head Length (mm)&quot;, main = &quot;Figure 8.6 (p.308)&quot;) 4.5.2 Box Plot: Check for Outliers Make box plots for x (total_l) and y (head_l), respectively. boxplot(x, main = &quot;Box Plot of Total Length (cm)&quot;) boxplot(y, main = &quot;Box Plot of Head Length (mm)&quot;) 4.5.3 Density Plot: Check for Normality Make density plots for x (total_l) and y (head_l), respectively. plot(density(x), main = &quot;Density Plot of Total Length (cm)&quot;) plot(density(y), main = &quot;Density Plot of Head Length (mm)&quot;) 4.6 Linear Regression 4.6.1 Model Fit the least squares regression \\[\\begin{align} head_l = \\beta_0 + \\beta_1 total_l + e. \\end{align}\\] # y ~ x fit &lt;- lm(head_l ~ total_l, data = possum_new) summary(fit) ## ## Call: ## lm(formula = head_l ~ total_l, data = possum_new) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.226 -1.593 -0.326 1.303 7.424 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 43.25900 5.41959 7.982 2.49e-12 *** ## total_l 0.56667 0.06206 9.131 7.95e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.618 on 100 degrees of freedom ## Multiple R-squared: 0.4547, Adjusted R-squared: 0.4492 ## F-statistic: 83.37 on 1 and 100 DF, p-value: 7.946e-15 We have \\[\\begin{align} \\hat{\\beta}_0 &amp; = 43.25900 \\\\ \\hat{\\beta}_1 &amp; = 0.56667. \\end{align}\\] 4.6.2 Residual Analysis Make a scatterplot and a residual plot for regression. Discuss whether fitting a linear model would be appropriate. # scatterplot scatter.smooth(x = x, y = y, xlab = &quot;Total Length (cm)&quot;, ylab = &quot;Head Length (mm)&quot;, main = &quot;Scatterplot - Figure 8.6 (p.308)&quot;) # residual plot plot(x = possum_new$total_l, y = fit$residuals, xlab = &quot;Total Length (cm)&quot;, ylab = &quot;Residuals&quot;, main = &quot;Residual Plot - Figure 8.7 (p.309)&quot;) abline(h=0) # density plot plot(density(fit$residuals), main = &quot;Density Plot of Residuals&quot;) Check the following conditions: Linearity: linear trend, i.e., no patterns in residual plot. (valid) Normal residuals: no extremely large or small residuals. (valid) Constant variability: points around line dispersed in similar way. (valid) Independent observations: occurrence of one observation provides no information about occurence of the other. (valid) Thus, fitting a linear model would be appropriate for this case. "]]
